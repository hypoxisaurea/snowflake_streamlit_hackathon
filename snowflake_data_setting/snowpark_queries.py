from snowflake.snowpark.context import get_active_session
from snowflake.snowpark import Session
import pandas as pd
import streamlit as st
import os
from dotenv import load_dotenv

# ğŸ”Œ ì„¸ì…˜ ì—°ê²°: SiS ìš°ì„ , ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ì„¤ì • ì‹œë„
session = None
try:
    # 1. Streamlit in Snowflake í™˜ê²½ ì‹œë„
    session = get_active_session()
    st.success("â„ï¸ Streamlit in Snowflake í™˜ê²½ì—ì„œ í™œì„± Snowpark ì„¸ì…˜ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
except Exception:
    # 2. SiS ì‹¤íŒ¨ ì‹œ ë¡œì»¬ í™˜ê²½ ì„¤ì • ì‹œë„
    st.warning("Streamlit in Snowflake í™œì„± ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ ì„¤ì •ìœ¼ë¡œ ì„¸ì…˜ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    try:
        load_dotenv()
        connection_parameters = {
            "user": os.getenv("DB_USER"),
            "password": os.getenv("DB_PASSWORD"),
            "account": os.getenv("DB_ACCOUNT"),
            "warehouse": os.getenv("DB_WAREHOUSE"),
            "database": os.getenv("DB_DATABASE"),
            "schema": os.getenv("DB_SCHEMA"),
            "role": os.getenv("DB_ROLE"),
        }
        if not all(connection_parameters.values()):
            missing = [k for k, v in connection_parameters.items() if not v]
            st.error(f".env íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì— ë‹¤ìŒ Snowflake ì—°ê²° ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing)}")
            st.stop()

        session = Session.builder.configs(connection_parameters).create()
        st.success("âœ… ë¡œì»¬ ì„¤ì •(.env)ìœ¼ë¡œ Snowpark ì„¸ì…˜ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë¡œì»¬ ì„¤ì •ìœ¼ë¡œ Snowpark ì„¸ì…˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.exception(e)
        st.stop()

# ì„¸ì…˜ ìµœì¢… í™•ì¸
if not session:
    st.error("Snowpark ì„¸ì…˜ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.")
    st.stop()

# ğŸ§  ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ìºì‹±)
@st.cache_data(show_spinner="ğŸŒ€ [ìœ„ì¹˜ ê¸°ë°˜] ë°±í™”ì  ì„ í˜¸ë„ ì ìˆ˜ë¥¼ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤...")
def get_store_score(res_dong: str, work_dong: str) -> pd.DataFrame:
    """
    ê±°ì£¼ì§€ì™€ ì§ì¥ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°±í™”ì ë³„ ì„ í˜¸ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    LOC_TYPE: 1=ê±°ì£¼ì§€ ê¸°ì¤€, 2=ì§ì¥ì§€ ê¸°ì¤€
    ì ìˆ˜ = ê±°ì£¼ì§€ ë¹„ìœ¨ * 0.6 + ì§ì¥ì§€ ë¹„ìœ¨ * 0.4
    """
    if not session:
        st.error("Snowpark ì„¸ì…˜ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return pd.DataFrame({'DEP_NAME': [], 'score': []})

    # ì£¼ê±°ì§€ ê¸°ì¤€ ì¿¼ë¦¬
    query_home = f"""
    SELECT DEP_NAME, RATIO
    FROM SNOWFLAKE_STREAMLIT_HACKATHON_LOPLAT_HOME_OFFICE_RATIO
    WHERE ADDR_LV3 = '{res_dong}' AND LOC_TYPE = 1
    """
    try:
        home_df = session.sql(query_home).to_pandas()
    except Exception as e:
        st.error(f"ê±°ì£¼ì§€ ê¸°ë°˜ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        home_df = pd.DataFrame({'DEP_NAME': [], 'RATIO': []})

    # ì§ì¥ì§€ ê¸°ì¤€ ì¿¼ë¦¬
    query_work = f"""
    SELECT DEP_NAME, RATIO
    FROM SNOWFLAKE_STREAMLIT_HACKATHON_LOPLAT_HOME_OFFICE_RATIO
    WHERE ADDR_LV3 = '{work_dong}' AND LOC_TYPE = 2
    """
    try:
        work_df = session.sql(query_work).to_pandas()
    except Exception as e:
        st.error(f"ì§ì¥ì§€ ê¸°ë°˜ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        work_df = pd.DataFrame({'DEP_NAME': [], 'RATIO': []})

    # ì ìˆ˜ ê²°í•© ê³„ì‚°
    if home_df.empty and work_df.empty:
        return pd.DataFrame({'DEP_NAME': [], 'score': []})
    elif home_df.empty:
        merged = work_df.rename(columns={'RATIO': 'RATIO_work'})
        merged['RATIO_home'] = 0
    elif work_df.empty:
        merged = home_df.rename(columns={'RATIO': 'RATIO_home'})
        merged['RATIO_work'] = 0
    else:
        merged = pd.merge(home_df, work_df, on="DEP_NAME", how="outer", suffixes=("_home", "_work")).fillna(0)

    # ì ìˆ˜ ê³„ì‚° (RATIO_home ë˜ëŠ” RATIO_workê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
    merged["score"] = merged.get("RATIO_home", 0) * 0.6 + merged.get("RATIO_work", 0) * 0.4
    merged = merged.sort_values("score", ascending=False)

    # ë°±í™”ì  ì´ë¦„ ë§¤í•‘
    store_name_map = {
        'ë¡¯ë°ë°±í™”ì _ë³¸ì ': 'ë¡¯ë°ë°±í™”ì ',
        'ì‹ ì„¸ê³„_ê°•ë‚¨': 'ì‹ ì„¸ê³„ë°±í™”ì ',
        'ë”í˜„ëŒ€ì„œìš¸': 'í˜„ëŒ€ë°±í™”ì '
    }
    if 'DEP_NAME' in merged.columns:
        merged['DEP_NAME'] = merged['DEP_NAME'].replace(store_name_map)
    else:
        st.warning("ê²°ê³¼ì— DEP_NAME ì»¬ëŸ¼ì´ ì—†ì–´ ë°±í™”ì  ì´ë¦„ì„ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame({'DEP_NAME': [], 'score': []})

    return merged[['DEP_NAME', 'score']]

# ğŸ§  ì†Œë¹„ë ¥ ì¶”ì • í•¨ìˆ˜ (ìºì‹±)
@st.cache_data(show_spinner="ğŸ’³ [ìœ„ì¹˜ ê¸°ë°˜] í‰ê·  ì†Œë¹„ë ¥ì„ ì¶”ì • ì¤‘ì…ë‹ˆë‹¤...")
def get_estimated_spending(res_dong: str) -> int:
    """
    ê±°ì£¼ì§€ ë™(dong)ì„ ê¸°ì¤€ìœ¼ë¡œ 'dong_features' í…Œì´ë¸”ì—ì„œ
    í‰ê·  ë°±í™”ì  ì†Œë¹„ì•¡(AVG_DEPARTMENT_STORE_SALES)ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    if not session:
        st.error("Snowpark ì„¸ì…˜ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return 0

    query = f"""
    SELECT AVG_DEPARTMENT_STORE_SALES
    FROM dong_features
    WHERE DONG = '{res_dong}'
    """
    try:
        df = session.sql(query).to_pandas()
        if df.empty or pd.isna(df.iloc[0, 0]):
            st.warning(f"'{res_dong}'ì— ëŒ€í•œ ì†Œë¹„ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        avg_sales = df.iloc[0, 0]
        if isinstance(avg_sales, (int, float)):
            return int(avg_sales)
        else:
            st.warning(f"'{res_dong}'ì˜ ì†Œë¹„ë ¥ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {avg_sales}")
            return 0
    except Exception as e:
        st.error(f"ì†Œë¹„ë ¥ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0 